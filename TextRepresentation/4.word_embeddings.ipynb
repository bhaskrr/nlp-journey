{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings\n",
    "\n",
    "A word embedding is a learned representation for text where words that have the same meaning have a similar representation. Word embeddings are in fact a class of techniques where individual words are represented as real-valued vectors in a predefined vector space. Each word is mapped to one vector and the vector values are learned in a way that resembles a neural network, and hence the technique is often lumped into the field of deep learning.\n",
    "\n",
    "Key to the approach is the idea of using a dense distributed representation for each word.\n",
    "\n",
    "Each word is represented by a real-valued vector, often tens or hundreds of dimensions. This is contrasted to the thousands or millions of dimensions required for sparse word representations, such as a one-hot encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding Algorithms\n",
    "\n",
    "Word embedding methods learn a real-valued vector representation for a predefined fixed sized vocabulary from a corpus of text.\n",
    "\n",
    "The learning process is either joint with the neural network model on some task, such as document classification, or is an unsupervised process, using document statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Embedding Layer\n",
    "\n",
    "An embedding layer is a word embedding that is learned jointly with a neural network model on a specific natural language processing task, such as language modeling or document classification.\n",
    "\n",
    "It requires that document text be cleaned and prepared such that each word is one-hot encoded. The size of the vector space is specified as part of the model, such as 50, 100, or 300 dimensions. The vectors are initialized with small random numbers. The embedding layer is used on the front end of a neural network and is fit in a supervised way using the Backpropagation algorithm.\n",
    "\n",
    "The one-hot encoded words are mapped to word vectors. If a multilayer Perceptron model is used, then the word vectors are concatenated before being fed as input to the model. If a recurrent neural network is used, then each word may be taken as one input in a sequence.\n",
    "\n",
    "This approach of learning an embedding layer requires a lot of training data and can be slow, but will learn an embedding both targeted to the specific text data and the NLP task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings with keras embedding layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-02 18:37:39.754778: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-02 18:37:39.770769: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-02 18:37:39.775547: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-02 18:37:39.788310: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-02 18:37:40.577499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define documents and their class labels\n",
    "docs = [\n",
    "    \"Better\",\n",
    "    \"Very good\",\n",
    "    \"Very bad\",\n",
    "    \"Not good\",\n",
    "]\n",
    "\n",
    "labels = np.array([1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7], [3, 5], [3, 8], [7, 5]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integer encode the documents\n",
    "vocab_size = 10\n",
    "\n",
    "encoded_docs = [one_hot(d, vocab_size) for d in docs]\n",
    "\n",
    "encoded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 0],\n",
       "       [3, 5],\n",
       "       [3, 8],\n",
       "       [7, 5]], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the encoded documents\n",
    "max_seq_length = 2\n",
    "\n",
    "padded_docs = pad_sequences(\n",
    "    encoded_docs,\n",
    "    maxlen=max_seq_length,\n",
    "    padding='post',\n",
    ")\n",
    "\n",
    "padded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735802151.138662   65547 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-01-02 12:45:51.178389: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, 10, name=\"Embedding\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "# summarize the model\n",
    "print(model.summary())\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7c6d8fe06e90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "model.fit(padded_docs, labels, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.6671\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "loss, accuracy = model.evaluate(padded_docs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text:  Better\n",
      "Embedding:  [-0.07710525 -0.02026236 -0.09089855 -0.05845061  0.03797184 -0.01143428\n",
      "  0.01129477  0.06135195 -0.06783418  0.04695345]\n",
      "\n",
      "\n",
      "Text:  Very good\n",
      "Embedding:  [-0.03838678 -0.03468434  0.04520625 -0.02773925  0.02169904 -0.0072412\n",
      " -0.01659951 -0.00625806  0.01756641 -0.03885076]\n",
      "\n",
      "\n",
      "Text:  Very bad\n",
      "Embedding:  [-0.01308181 -0.02019053  0.00647775 -0.04517845  0.03884784 -0.00561903\n",
      "  0.00522054  0.00304848  0.00430051  0.00708648]\n",
      "\n",
      "\n",
      "Text:  Not good\n",
      "Embedding:  [ 0.04171123 -0.03233737  0.00376484 -0.03827902  0.01265317  0.02723996\n",
      " -0.03754312 -0.00821873 -0.03979775  0.00343524]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the learned embeddings from the embedding layer\n",
    "for i in range(len(docs)):\n",
    "    print(\"Text: \", docs[i])\n",
    "    print(\"Embedding: \", model.get_layer(\"Embedding\").weights[0][i].numpy())\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Word2Vec\n",
    "\n",
    "Developed by Tomas Mikolov, et al. at Google in 2013, Word2Vec is a statistical method for efficiently learning a standalone word embedding from a text corpus.\n",
    "\n",
    "Two different learning models were introduced that can be used as part of the word2vec approach to learn the word embedding; they are:\n",
    "\n",
    "1. Continuous Bag-of-Words, or CBOW model.\n",
    "2. Continuous Skip-Gram Model.\n",
    "\n",
    "The CBOW model learns the embedding by predicting the current word based on its context. The continuous skip-gram model learns by predicting the surrounding words given a current word.\n",
    "\n",
    "Both models are focused on learning about words given their local usage context, where the context is defined by a window of neighboring words. This window is a configurable parameter of the model.\n",
    "\n",
    "The key benefit of the approach is that high-quality word embeddings can be learned efficiently (low space and time complexity), allowing larger embeddings to be learned (more dimensions) from much larger corpora of text (billions of words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec with Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load spacy's english model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Metadata</th>\n",
       "      <th>Time</th>\n",
       "      <th>Pictures</th>\n",
       "      <th>7514</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Rusha Chakraborty</td>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>5</td>\n",
       "      <td>1 Review , 2 Followers</td>\n",
       "      <td>5/25/2019 15:54</td>\n",
       "      <td>0</td>\n",
       "      <td>2447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Anusha Tirumalaneedi</td>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>5</td>\n",
       "      <td>3 Reviews , 2 Followers</td>\n",
       "      <td>5/25/2019 14:20</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Ashok Shekhawat</td>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>5</td>\n",
       "      <td>2 Reviews , 3 Followers</td>\n",
       "      <td>5/24/2019 22:54</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Swapnil Sarkar</td>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>5</td>\n",
       "      <td>1 Review , 1 Follower</td>\n",
       "      <td>5/24/2019 22:11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Dileep</td>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>3 Reviews , 2 Followers</td>\n",
       "      <td>5/24/2019 21:37</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Restaurant              Reviewer  \\\n",
       "0  Beyond Flavours     Rusha Chakraborty   \n",
       "1  Beyond Flavours  Anusha Tirumalaneedi   \n",
       "2  Beyond Flavours       Ashok Shekhawat   \n",
       "3  Beyond Flavours        Swapnil Sarkar   \n",
       "4  Beyond Flavours                Dileep   \n",
       "\n",
       "                                              Review Rating  \\\n",
       "0  The ambience was good, food was quite good . h...      5   \n",
       "1  Ambience is too good for a pleasant evening. S...      5   \n",
       "2  A must try.. great food great ambience. Thnx f...      5   \n",
       "3  Soumen das and Arun was a great guy. Only beca...      5   \n",
       "4  Food is good.we ordered Kodi drumsticks and ba...      5   \n",
       "\n",
       "                  Metadata             Time  Pictures    7514  \n",
       "0   1 Review , 2 Followers  5/25/2019 15:54         0  2447.0  \n",
       "1  3 Reviews , 2 Followers  5/25/2019 14:20         0     NaN  \n",
       "2  2 Reviews , 3 Followers  5/24/2019 22:54         0     NaN  \n",
       "3    1 Review , 1 Follower  5/24/2019 22:11         0     NaN  \n",
       "4  3 Reviews , 2 Followers  5/24/2019 21:37         0     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the inspecting the data\n",
    "data = pd.read_csv(\"./restaurant_reviews.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Rating\n",
       "0  The ambience was good, food was quite good . h...      5\n",
       "1  Ambience is too good for a pleasant evening. S...      5\n",
       "2  A must try.. great food great ambience. Thnx f...      5\n",
       "3  Soumen das and Arun was a great guy. Only beca...      5\n",
       "4  Food is good.we ordered Kodi drumsticks and ba...      5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the required columns\n",
    "review_rating_data = data[[\"Review\", \"Rating\"]]\n",
    "review_rating_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review    45\n",
      "Rating    38\n",
      "dtype: int64\n",
      "Review    0\n",
      "Rating    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(review_rating_data.isna().sum())\n",
    "\n",
    "# Drop rows with null values\n",
    "review_rating_data = review_rating_data.dropna()\n",
    "\n",
    "print(review_rating_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "5       3826\n",
       "4       2373\n",
       "1       1735\n",
       "3       1192\n",
       "2        684\n",
       "4.5       69\n",
       "3.5       47\n",
       "2.5       19\n",
       "1.5        9\n",
       "Like       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the class distribution\n",
    "review_rating_data[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '4', '1', '3', '2', '3.5', '4.5', '2.5', '1.5', 'Like'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique ratins in data\n",
    "review_rating_data[\"Rating\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_159531/4064195984.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_rating_1_to_5_data[\"Rating\"] = review_rating_1_to_5_data[\"Rating\"].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  The ambience was good, food was quite good . h...       5\n",
       "1  Ambience is too good for a pleasant evening. S...       5\n",
       "2  A must try.. great food great ambience. Thnx f...       5\n",
       "3  Soumen das and Arun was a great guy. Only beca...       5\n",
       "4  Food is good.we ordered Kodi drumsticks and ba...       5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows with rating values in integers between 1 and 5\n",
    "review_rating_1_to_5_data = review_rating_data[review_rating_data[\"Rating\"].isin([\"1\", \"2\", \"3\", \"4\", \"5\"])]\n",
    "\n",
    "# Convert the ratings from strings to integers\n",
    "review_rating_1_to_5_data[\"Rating\"] = review_rating_1_to_5_data[\"Rating\"].astype(int)\n",
    "\n",
    "review_rating_1_to_5_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_159531/2887753607.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_rating_1_to_5_data[\"clean_text\"] = review_rating_1_to_5_data[\"Review\"].apply(lambda x: preprocess(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>5</td>\n",
       "      <td>the ambience was good food was quite good had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>5</td>\n",
       "      <td>ambience is too good for a pleasant evening se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>5</td>\n",
       "      <td>a must try great food great ambience thnx for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>5</td>\n",
       "      <td>soumen das and arun was a great guy only becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>food is ordered kodi drumsticks and basket mut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  \\\n",
       "0  The ambience was good, food was quite good . h...       5   \n",
       "1  Ambience is too good for a pleasant evening. S...       5   \n",
       "2  A must try.. great food great ambience. Thnx f...       5   \n",
       "3  Soumen das and Arun was a great guy. Only beca...       5   \n",
       "4  Food is good.we ordered Kodi drumsticks and ba...       5   \n",
       "\n",
       "                                          clean_text  \n",
       "0  the ambience was good food was quite good had ...  \n",
       "1  ambience is too good for a pleasant evening se...  \n",
       "2  a must try great food great ambience thnx for ...  \n",
       "3  soumen das and arun was a great guy only becau...  \n",
       "4  food is ordered kodi drumsticks and basket mut...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to preprocess the Reviews\n",
    "def preprocess(text):\n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Apply lowercasing and lemmatization if the token is alphanumeric and is not a punctuation\n",
    "    processed_tokens = [token.lemma_ and token.lower_ for token in doc if token.is_alpha and not token.is_punct]\n",
    "    # Join the token to form a string\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "# Apply preprocessing function to the dataframe\n",
    "review_rating_1_to_5_data[\"clean_text\"] = review_rating_1_to_5_data[\"Review\"].apply(lambda x: preprocess(x))\n",
    "\n",
    "review_rating_1_to_5_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sentences and create the word2vec model\n",
    "tokenized_sentences = [sentence.split() for sentence in review_rating_1_to_5_data[\"clean_text\"]]\n",
    "\n",
    "model = Word2Vec(sentences= tokenized_sentences, vector_size=100, window=5, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pathetic', 0.8896403312683105),\n",
       " ('horrible', 0.8505977988243103),\n",
       " ('disappointing', 0.8138681650161743),\n",
       " ('disappointed', 0.7905276417732239),\n",
       " ('worst', 0.7878928780555725),\n",
       " ('poor', 0.7844704389572144),\n",
       " ('delivered', 0.7485617399215698),\n",
       " ('totally', 0.6707685589790344),\n",
       " ('stale', 0.6638467907905579),\n",
       " ('hopeless', 0.6579142212867737)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar words to \"bad\"\n",
    "model.wv.most_similar(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('great', 0.8610652089118958),\n",
       " ('decent', 0.8579275012016296),\n",
       " ('nice', 0.8251969814300537),\n",
       " ('tasty', 0.7953647971153259),\n",
       " ('average', 0.7688118815422058),\n",
       " ('awesome', 0.7533378005027771),\n",
       " ('superb', 0.7504878044128418),\n",
       " ('reasonable', 0.7422598600387573),\n",
       " ('excellent', 0.7314729690551758),\n",
       " ('okay', 0.7286348342895508)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similar words to \"good\"\n",
    "model.wv.most_similar(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31629485"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Similarity between words\n",
    "model.wv.similarity(\"great\", \"worse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. GloVe\n",
    "\n",
    "The Global Vectors for Word Representation, or GloVe algorithm is an extension to the word2vec method for efficiently learning word vectors, developed by Jeffrey Pennington, et al. at Stanford.\n",
    "\n",
    "The Local context window method carries over from previous architectures like CBOW and Skip-gram, while the addition of a co-occurrence factor differentiates it from other architectures. For its training phase, instead of continuously iterating over local windows of sequenced data, we use the co-occurrence matrix as a lookup table for words which have appeared in the context of other words, as well as prevent computation for words who have no co-occurrence.\n",
    "\n",
    "Refer to the article [An Introduction to the Global Vectors (GloVe) Algorithm](https://wandb.ai/authors/embeddings-2/reports/An-Introduction-to-the-Global-Vectors-GloVe-Algorithm--VmlldzozNDg2NTQ) for a detailed explanation of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe with SpaCy\n",
    "\n",
    "SpaCy uses GloVe as their word emebdding technique. The `md` and `lg` pipelines include these pretrained embeddings of dimension 300.\n",
    "\n",
    "Read More: [SpaCy Docs](https://spacy.io/models/en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model with vectorization capabilities\n",
    "nlp_spacy = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cattle <-> dog: 0.37324426422166307\n",
      "cattle <-> bull: 0.5753979290259077\n",
      "cattle <-> apple: 0.2718477134788411\n",
      "cattle <-> cat: 0.37324426422166307\n",
      "cattle <-> human: 0.4285642343021014\n",
      "cattle <-> cow: 0.7115770080910545\n",
      "cattle <-> queen: 0.14657561883084586\n",
      "cattle <-> car: 0.11678962999464032\n",
      "cattle <-> plate: 0.13935583061777815\n",
      "cattle <-> farm: 0.5867184930936868\n",
      "cattle <-> milk: 0.4520342462205761\n"
     ]
    }
   ],
   "source": [
    "# Function to compare similarity between a base word and the specified words\n",
    "def print_similarity(base_word: str, words_to_compare: str):\n",
    "    base_token = nlp_spacy(base_word)\n",
    "    \n",
    "    word_tokens = nlp_spacy(words_to_compare)\n",
    "    \n",
    "    for word_token in word_tokens:\n",
    "        print(f\"{base_token.text} <-> {word_token.text}:\", base_token.similarity(word_token))\n",
    "        \n",
    "# Compare and print similarity scores\n",
    "print_similarity(\"cattle\", \"dog bull apple cat human cow queen car plate farm milk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText\n",
    "\n",
    "As the official documentation says, \"FastText is an open-source, free, lightweight library that allows users to learn text representations and text classifiers. It works on standard, generic hardware. Models can later be reduced in size to even fit on mobile devices.\"\n",
    "\n",
    "This model allows creating unsupervised learning or supervised learning algorithm for obtaining vector representations for words. FastText supports both CBOW and Skip-gram models.\n",
    "\n",
    "Read More : [Geeksforgeeks](https://www.geeksforgeeks.org/fasttext-working-and-implementation/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import fasttext\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Description</th>\n",
       "      <th>Nearest Town</th>\n",
       "      <th>Themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balpakram</td>\n",
       "      <td>SOUTH GARO HILLS</td>\n",
       "      <td>Balpakram, ‘the land of perpetual winds’, may ...</td>\n",
       "      <td>Baghmara (60 kms),  Williamnagar (127 kms)</td>\n",
       "      <td>Hiking, Trekking, Wildlife, Folklore, Landscapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chandigre Rural Village</td>\n",
       "      <td>WEST GARO HILLS</td>\n",
       "      <td>Chandigre embraces you with its orchards and p...</td>\n",
       "      <td>Tura (30 Kms)</td>\n",
       "      <td>Culture, Sight Seeing, Cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nokrek Biosphere Reserve</td>\n",
       "      <td>WEST GARO HILLS</td>\n",
       "      <td>Let the wildest corners of Meghalaya embrace y...</td>\n",
       "      <td>Tura (45 Kms)</td>\n",
       "      <td>Nature, Outdoors, Camping, Trekking, Photograp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tura Peak</td>\n",
       "      <td>West Garo Hills</td>\n",
       "      <td>At close to 900 metres above sea level, Tura P...</td>\n",
       "      <td>Tura (4 kms)</td>\n",
       "      <td>Nature, Sightseeing, Treks and Hikes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Siju Caves and Rock Formations</td>\n",
       "      <td>West Garo Hills</td>\n",
       "      <td>Visiting Siju Cave is like entering the belly ...</td>\n",
       "      <td>Baghmara (33Kms)</td>\n",
       "      <td>Nature Walks, Hikes, Caving</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name            Region  \\\n",
       "0                       Balpakram  SOUTH GARO HILLS   \n",
       "1         Chandigre Rural Village   WEST GARO HILLS   \n",
       "2        Nokrek Biosphere Reserve   WEST GARO HILLS   \n",
       "3                       Tura Peak   West Garo Hills   \n",
       "4  Siju Caves and Rock Formations   West Garo Hills   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Balpakram, ‘the land of perpetual winds’, may ...   \n",
       "1  Chandigre embraces you with its orchards and p...   \n",
       "2  Let the wildest corners of Meghalaya embrace y...   \n",
       "3  At close to 900 metres above sea level, Tura P...   \n",
       "4  Visiting Siju Cave is like entering the belly ...   \n",
       "\n",
       "                                 Nearest Town  \\\n",
       "0  Baghmara (60 kms),  Williamnagar (127 kms)   \n",
       "1                               Tura (30 Kms)   \n",
       "2                               Tura (45 Kms)   \n",
       "3                                Tura (4 kms)   \n",
       "4                            Baghmara (33Kms)   \n",
       "\n",
       "                                              Themes  \n",
       "0   Hiking, Trekking, Wildlife, Folklore, Landscapes  \n",
       "1                     Culture, Sight Seeing, Cuisine  \n",
       "2  Nature, Outdoors, Camping, Trekking, Photograp...  \n",
       "3               Nature, Sightseeing, Treks and Hikes  \n",
       "4                        Nature Walks, Hikes, Caving  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and inspecting data\n",
    "dataset = pd.read_csv(\"./destinations.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Region</th>\n",
       "      <th>Description</th>\n",
       "      <th>Nearest Town</th>\n",
       "      <th>Themes</th>\n",
       "      <th>cleaned_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balpakram</td>\n",
       "      <td>SOUTH GARO HILLS</td>\n",
       "      <td>Balpakram, ‘the land of perpetual winds’, may ...</td>\n",
       "      <td>Baghmara (60 kms),  Williamnagar (127 kms)</td>\n",
       "      <td>Hiking, Trekking, Wildlife, Folklore, Landscapes</td>\n",
       "      <td>balpakram land perpetual wind know outside wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chandigre Rural Village</td>\n",
       "      <td>WEST GARO HILLS</td>\n",
       "      <td>Chandigre embraces you with its orchards and p...</td>\n",
       "      <td>Tura (30 Kms)</td>\n",
       "      <td>Culture, Sight Seeing, Cuisine</td>\n",
       "      <td>chandigre embrace orchard plantation offer vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nokrek Biosphere Reserve</td>\n",
       "      <td>WEST GARO HILLS</td>\n",
       "      <td>Let the wildest corners of Meghalaya embrace y...</td>\n",
       "      <td>Tura (45 Kms)</td>\n",
       "      <td>Nature, Outdoors, Camping, Trekking, Photograp...</td>\n",
       "      <td>let wild corner meghalaya embrace nokrek land ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tura Peak</td>\n",
       "      <td>West Garo Hills</td>\n",
       "      <td>At close to 900 metres above sea level, Tura P...</td>\n",
       "      <td>Tura (4 kms)</td>\n",
       "      <td>Nature, Sightseeing, Treks and Hikes</td>\n",
       "      <td>close metre sea level tura peak haven nature l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Siju Caves and Rock Formations</td>\n",
       "      <td>West Garo Hills</td>\n",
       "      <td>Visiting Siju Cave is like entering the belly ...</td>\n",
       "      <td>Baghmara (33Kms)</td>\n",
       "      <td>Nature Walks, Hikes, Caving</td>\n",
       "      <td>visit siju cave like enter belly earth place u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Name            Region  \\\n",
       "0                       Balpakram  SOUTH GARO HILLS   \n",
       "1         Chandigre Rural Village   WEST GARO HILLS   \n",
       "2        Nokrek Biosphere Reserve   WEST GARO HILLS   \n",
       "3                       Tura Peak   West Garo Hills   \n",
       "4  Siju Caves and Rock Formations   West Garo Hills   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Balpakram, ‘the land of perpetual winds’, may ...   \n",
       "1  Chandigre embraces you with its orchards and p...   \n",
       "2  Let the wildest corners of Meghalaya embrace y...   \n",
       "3  At close to 900 metres above sea level, Tura P...   \n",
       "4  Visiting Siju Cave is like entering the belly ...   \n",
       "\n",
       "                                 Nearest Town  \\\n",
       "0  Baghmara (60 kms),  Williamnagar (127 kms)   \n",
       "1                               Tura (30 Kms)   \n",
       "2                               Tura (45 Kms)   \n",
       "3                                Tura (4 kms)   \n",
       "4                            Baghmara (33Kms)   \n",
       "\n",
       "                                              Themes  \\\n",
       "0   Hiking, Trekking, Wildlife, Folklore, Landscapes   \n",
       "1                     Culture, Sight Seeing, Cuisine   \n",
       "2  Nature, Outdoors, Camping, Trekking, Photograp...   \n",
       "3               Nature, Sightseeing, Treks and Hikes   \n",
       "4                        Nature Walks, Hikes, Caving   \n",
       "\n",
       "                                 cleaned_description  \n",
       "0  balpakram land perpetual wind know outside wor...  \n",
       "1  chandigre embrace orchard plantation offer vis...  \n",
       "2  let wild corner meghalaya embrace nokrek land ...  \n",
       "3  close metre sea level tura peak haven nature l...  \n",
       "4  visit siju cave like enter belly earth place u...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_punct and not token.is_stop]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "dataset[\"cleaned_description\"] = dataset[\"Description\"].map(preprocess)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned column data in a .txt file\n",
    "dataset.to_csv(\"descriptions.txt\", columns=[\"cleaned_description\"], header=None, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  268\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:   22312 lr:  0.000000 avg.loss:  3.441816 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "# Train the fasttext model\n",
    "model = fasttext.train_unsupervised(\"./descriptions.txt\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.99995356798172, 'khasis'),\n",
       " (0.9999534487724304, 'traveller'),\n",
       " (0.999952495098114, 'recommend'),\n",
       " (0.9999517202377319, 'destination'),\n",
       " (0.9999501705169678, 'plantation'),\n",
       " (0.99994957447052, 'attraction'),\n",
       " (0.9999493360519409, 'formation'),\n",
       " (0.9999487400054932, 'treasure'),\n",
       " (0.999947726726532, 'tradition'),\n",
       " (0.9999430179595947, 'architecture')]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get words with similar context\n",
    "model.get_nearest_neighbors(\"khasi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.20197023,  0.17617416,  0.08068047,  0.11070824,  0.19241388,\n",
       "        0.01129809, -0.22083907, -0.12746342,  0.06052846,  0.1549456 ,\n",
       "        0.1012831 ,  0.11436604, -0.13146098, -0.18188925, -0.22904748,\n",
       "       -0.11884536, -0.12715411,  0.02678535, -0.20266566, -0.11177896,\n",
       "       -0.08973555,  0.05524326, -0.10699264, -0.2871318 , -0.03043975,\n",
       "       -0.06358921, -0.01478999,  0.03898263,  0.14424844, -0.01696146,\n",
       "        0.12651022, -0.06660443, -0.25168055, -0.32347286, -0.3151858 ,\n",
       "        0.01121099, -0.04445335, -0.01124603, -0.07693978, -0.14432028,\n",
       "        0.04505534, -0.08532544, -0.14645019,  0.05692603,  0.16317284,\n",
       "       -0.10321926, -0.13984707, -0.08069222,  0.11256304, -0.1632185 ,\n",
       "       -0.03277909,  0.07627474,  0.05831416, -0.14088678,  0.00734389,\n",
       "       -0.32635668,  0.03101291,  0.07308933,  0.1893121 ,  0.16665672,\n",
       "        0.17646423, -0.09076812, -0.00261026, -0.20751126, -0.11095194,\n",
       "       -0.09241136, -0.07137716,  0.34361228, -0.20824572,  0.07029191,\n",
       "        0.04688931, -0.11554229,  0.01150064, -0.24439333,  0.07413588,\n",
       "       -0.07602803,  0.31411058,  0.01687625,  0.11812972,  0.12273053,\n",
       "       -0.01090858, -0.14123176,  0.11246669,  0.11832306,  0.03648999,\n",
       "        0.12422685, -0.15049207, -0.2101768 , -0.00708185,  0.0886407 ,\n",
       "        0.22818443,  0.19914477,  0.24812621, -0.04957417,  0.03026885,\n",
       "        0.16353695, -0.05571849,  0.13667667,  0.21815938, -0.04004207],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get word vectors\n",
    "model.get_word_vector(\"garo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>',\n",
       " 'lake',\n",
       " 'fall',\n",
       " 'forest',\n",
       " 'place',\n",
       " 'hill',\n",
       " 'bridge',\n",
       " 'meghalaya',\n",
       " 'river',\n",
       " 'village',\n",
       " 'water',\n",
       " 'shillong',\n",
       " 'cave',\n",
       " 'enjoy',\n",
       " 'waterfall',\n",
       " 'visitor',\n",
       " 'view',\n",
       " 'provide',\n",
       " 'local',\n",
       " 'close']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First few words from the vocabulary\n",
    "model.words[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance of Word Embeddings\n",
    "\n",
    "* Capturing semantic meaning: Word embeddings allow us to quantify and categorize semantic similarities between linguistic items. They provide a rich representation of words where the semantics are embedded in the dimensions of the vector space, making it possible for algorithms to understand the relationships between words.\n",
    "\n",
    "* Dimensionality reduction: In contrast to traditional bag-of-words models, where each unique word in the corpus is assigned a unique dimension, word embeddings map words into a lower-dimensional space where the dimensions represent semantic features. This makes word embeddings more computationally efficient.\n",
    "\n",
    "* Handling large vocabularies: Traditional text representation techniques struggle in the face of vast vocabularies, due to the curse of dimensionality and sparsity issues. By representing words as dense vectors, word embeddings can handle large vocabularies efficiently.\n",
    "\n",
    "* Enabling transfer learning: This is a machine learning technique where pre-trained models are used on a new, but related problem. Pre-trained word embeddings learned from large datasets can be leveraged to improve performance on smaller, related tasks. This can significantly reduce the effort of creating new NLP models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "1. Machine Learning Mastery: [What Are Word Embeddings for Text?](https://machinelearningmastery.com/what-are-word-embeddings/), [How to Use Word Embedding Layers for Deep Learning with Keras](https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/)\n",
    "2. Medium: [A Dummy’s Guide to Word2Vec](https://medium.com/@manansuri/a-dummys-guide-to-word2vec-456444f3c673)\n",
    "3. GloVe Embeddings: [Official Site](https://nlp.stanford.edu/projects/glove/)\n",
    "4. Youtube: Codebasics\n",
    "5. Datasets: [Restaurant Reviews Dataset](https://www.kaggle.com/datasets/joebeachcapital/restaurant-reviews), [Meghalaya Destinations Dataset](https://www.kaggle.com/datasets/bhaskarbordoloi/meghalaya-destinations-dataset/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
