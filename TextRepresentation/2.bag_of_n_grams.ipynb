{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of N-Grams\n",
    "\n",
    "In natural language processing (NLP), the Bag of N-Grams Model is a method for representing text input in an organized way that machine learning algorithms may exploit. An N-gram consists of a continuous series of 'N' elements from a specific voice or text sample. These objects may be words, syllables, or characters. To generate a feature set for text analysis, the model builds a \"bag\" that is, a collection of these N-grams.\n",
    "\n",
    "\n",
    "* Unigram (1-gram): \"I love NLP\" -> [\"I\", \"love\", \"NLP\"]\n",
    "\n",
    "* Bigram (2-gram): \"I love NLP\" -> [\"I love\", \"love NLP\"]\n",
    "\n",
    "* Trigram (3-gram): \"I love NLP\" -> [\"I love NLP\"]\n",
    "\n",
    "## Comparison with Bag of Words Model\n",
    "\n",
    "NLP core strategies include the Bag of Words (BoW) Model and the Bag of N-Grams Model, however they differ greatly from one another.\n",
    "\n",
    "1. Word Order: The BoW Model treats each word as an independent feature and disregards the word order within the text. By taking word sequences into account, however, the Bag of N-Grams Model manages to preserve a portion of the word order information.\n",
    "\n",
    "2. Context Capture: Because BoW just takes individual words into account, it is unable to capture context well. The Bag of N-Grams Model is more useful for jobs where word order matters because it incorporates word sequences, which capture local context.\n",
    "\n",
    "3. Dimensionality: When compared to the Bag of N-Grams Model, the BoW Model usually yields a lower-dimensional feature space, especially for higher values of N. This may result in problems with sparsity in the N-Grams Model's feature matrix.\n",
    "\n",
    "## Understanding N-Grams:\n",
    "\n",
    "Contiguous groups of n elements from a particular text or audio sample are known as N-grams. Text analysis, language modeling, and machine learning applications are only a few of the many uses for them in natural language processing (NLP). Depending on the value of n, there are several ways to conceptualize n-grams.\n",
    "\n",
    "1. Unigrams\n",
    "\n",
    "    When n = 1, a unigram is the most basic type of n-gram. They stand in for certain terms inside a document. Unigrams are helpful for simple text analysis tasks, but they frequently lack the context that word combinations give.\n",
    "\n",
    "    For example, in the sentence \"The cat sat on the mat,\" the unigrams are:\n",
    "\n",
    "    * \"The\"\n",
    "    * \"cat\"\n",
    "    * \"sat\"\n",
    "    * \"on\"\n",
    "    * \"the\"\n",
    "    * \"mat\"\n",
    "\n",
    "2. Bigrams\n",
    "\n",
    "    Bigrams consist of two neighboring words in succession (n = 2). They take into account word pairings to partially capture the context. Bigrams are useful for deciphering word connections in text because they offer more contextual information than unigrams.\n",
    "\n",
    "    Using the same sentence, the bigrams are:\n",
    "\n",
    "    * \"The cat\"\n",
    "    * \"cat sat\"\n",
    "    * \"sat on\"\n",
    "    * \"on the\"\n",
    "    * \"the mat\"\n",
    "\n",
    "3. Trigrams\n",
    "\n",
    "    Three words follow one another to form a trigram (n = 3). Because they identify triplet word sequences, they provide considerably more context. Trigrams are useful for more in-depth text analysis and language comprehension since they may capture trends at the phrase level.\n",
    "\n",
    "    From the example sentence, the trigrams are:\n",
    "\n",
    "    * \"The cat sat\"\n",
    "    * \"cat sat on\"\n",
    "    * \"sat on the\"\n",
    "    * \"on the mat\"\n",
    "\n",
    "4. Higher-order N-Grams\n",
    "\n",
    "    Higher-order n-grams (n > 3) expand on this idea by including four or more words. Higher-order n-grams have higher processing and data needs yet are capable of capturing intricate language patterns. They come in especially handy for specific NLP jobs where it's imperative to capture intricate context.\n",
    "\n",
    "    For instance, 4-grams (quad grams) for our sentence would be:\n",
    "\n",
    "    * \"The cat sat on\"\n",
    "    * \"cat sat on the\"\n",
    "    * \"sat on the mat\"\n",
    "\n",
    "## Generating N-Grams from Text\n",
    "\n",
    "Generating n-grams is the next step after preprocessing the text. N-grams are consecutive groups of n textual elements (words, letters, etc.).\n",
    "\n",
    "* Sliding Window Approach\n",
    "\n",
    "    To capture each n-gram, the sliding window method entails dragging a window of size n over the text. At a window size of 2 (bigrams), for example, the window records word pairs that follow one another.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Text: [\"natural\", \"language\", \"processing\", \"fascinating\"]\n",
    "    \n",
    "    Bigrams: [(\"natural\", \"language\"), (\"language\", \"processing\"), (\"processing\", \"fascinating\")]\n",
    "\n",
    "    For trigrams (n=3), the window captures triplets of consecutive words. \n",
    "\n",
    "## Handling Boundaries in Text\n",
    "\n",
    "Text boundaries must be handled carefully while creating n-grams, particularly for texts that are broken up into sentences or pages.\n",
    "\n",
    "* Sentence Limits: Make sure n-grams don't cross over into other phrases. It is best to handle each statement on its own.\n",
    "\n",
    "    Example:\n",
    "\n",
    "    Text: \"Natural Language Processing is fascinating. It has many applications.\"\n",
    "\n",
    "    Sentence 1 Bigrams: [(\"natural\", \"language\"), (\"language\", \"processing\"), (\"processing\", \"is\"), (\"is\", \"fascinating\")]\n",
    "\n",
    "    Sentence 2 Bigrams: [(\"it\", \"has\"), (\"has\", \"many\"), (\"many\", \"applications\")]\n",
    "    \n",
    "    Document Boundaries: Make sure that n-grams are created independently within each document if the text is separated among documents.\n",
    "\n",
    "## Vector Representation of Text\n",
    "\n",
    "Frequency Counts:\n",
    "\n",
    "Converting text into a numerical vector with each element representing the number of times an N-Gram appears in the text is the process of doing frequency counts. This approach offers a simple means of quantifying textual data.\n",
    "\n",
    "1. Tokenization: Tokenize the text by dividing it into discrete words or characters.\n",
    "\n",
    "2. Produce N-Grams: Construct N-word sequences. For instance, the sentence \"The cat sat\" produces \"The cat\" and \"cat sat\" for bigrams (N=2).\n",
    "\n",
    "3. Count Frequencies: Determine how many times each N-Gram appears in the text.\n",
    "\n",
    "Example:\n",
    "\n",
    "Sentences: \"I Love Natural Language Processing.\", \"It has many applications in various domains.\"\n",
    "\n",
    "After preprocessing the text will look like:\n",
    "\n",
    "\"love natural language processing\", \"many application various domain\"\n",
    "\n",
    "The bi-grams are:\n",
    "\n",
    "\"love natural\" \"natural language\" \"language processing\" \"many application\" \"application various\" \"various domain\"\n",
    "\n",
    "Feature Matrix is:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th rowspan=\"2\">Sentences</th>\n",
    "    <th colspan=\"6\">Features</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>love natural</th>\n",
    "    <th>natural language</th>\n",
    "    <th>language processing</th>\n",
    "    <th>many application</th>\n",
    "    <th>application various</th>\n",
    "    <th>various domain</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>love natural language processing</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>0</td>\n",
    "    <td>0</td>\n",
    "    <td>0</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>many application various domain</td>\n",
    "    <td>0</td>\n",
    "    <td>0</td>\n",
    "    <td>0</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "    <td>1</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "The feature vectors for each of the sentences are:\n",
    "* \"I Love Natural Language Processing.\" -> [1,1,1,0,0,0]\n",
    "\n",
    "* \"It has many applications in various domains.\" -> [0,0,0,1,1,1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams with NLTK and SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import spacy\n",
    "from nltk.util import ngrams\n",
    "\n",
    "# Load spacy's english model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=1 (unigram):  [(i,), (love,), (to,), (play,), (cricket,), (i,), (also,), (like,), (to,), (watch,), (football,), (tho,)]\n",
      "N=2 (bigram): [(i, love), (love, to), (to, play), (play, cricket), (i, also), (also, like), (like, to), (to, watch), (watch, football), (football, tho)]\n",
      "M=3 (trigram): [(i, love, to), (love, to, play), (to, play, cricket), (i, also, like), (also, like, to), (like, to, watch), (to, watch, football), (watch, football, tho)]\n"
     ]
    }
   ],
   "source": [
    "def generate_n_grams(text, n):\n",
    "    # Lowercase and split the text into sentences\n",
    "    text = text.lower()\n",
    "    sentences = text.split(\".\")\n",
    "    \n",
    "    n_gram_list = []\n",
    "    \n",
    "    # Compute n-grams for each sentence to preserve text boundaries\n",
    "    # and add them to n_gram_list\n",
    "    for sentence in sentences:\n",
    "        doc = nlp(sentence)\n",
    "    \n",
    "        # Include only alphanumeric characters and do not include punctuations\n",
    "        tokens = [token for token in doc if token.is_alpha and not token.is_punct]\n",
    "    \n",
    "        # Generate N-Grams\n",
    "        n_grams = ngrams(tokens, n)\n",
    "    \n",
    "        n_gram_list.extend(gram for gram in n_grams)\n",
    "\n",
    "    return n_gram_list\n",
    "\n",
    "\n",
    "sample_text = \"I love to play cricket. I also like to watch football tho.\"\n",
    "\n",
    "# Generate and print n-grams\n",
    "print(\"N=1 (unigram): \", generate_n_grams(sample_text, 1))\n",
    "print(\"N=2 (bigram):\", generate_n_grams(sample_text, 2))\n",
    "print(\"M=3 (trigram):\", generate_n_grams(sample_text, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis with N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Metadata</th>\n",
       "      <th>Time</th>\n",
       "      <th>Pictures</th>\n",
       "      <th>7514</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Rusha Chakraborty</td>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>5</td>\n",
       "      <td>1 Review , 2 Followers</td>\n",
       "      <td>5/25/2019 15:54</td>\n",
       "      <td>0</td>\n",
       "      <td>2447.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Anusha Tirumalaneedi</td>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>5</td>\n",
       "      <td>3 Reviews , 2 Followers</td>\n",
       "      <td>5/25/2019 14:20</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Ashok Shekhawat</td>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>5</td>\n",
       "      <td>2 Reviews , 3 Followers</td>\n",
       "      <td>5/24/2019 22:54</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Swapnil Sarkar</td>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>5</td>\n",
       "      <td>1 Review , 1 Follower</td>\n",
       "      <td>5/24/2019 22:11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Beyond Flavours</td>\n",
       "      <td>Dileep</td>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>3 Reviews , 2 Followers</td>\n",
       "      <td>5/24/2019 21:37</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Restaurant              Reviewer  ... Pictures    7514\n",
       "0  Beyond Flavours     Rusha Chakraborty  ...        0  2447.0\n",
       "1  Beyond Flavours  Anusha Tirumalaneedi  ...        0     NaN\n",
       "2  Beyond Flavours       Ashok Shekhawat  ...        0     NaN\n",
       "3  Beyond Flavours        Swapnil Sarkar  ...        0     NaN\n",
       "4  Beyond Flavours                Dileep  ...        0     NaN\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the inspecting the data\n",
    "data = pd.read_csv(\"./restaurant_reviews.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Rating\n",
       "0  The ambience was good, food was quite good . h...      5\n",
       "1  Ambience is too good for a pleasant evening. S...      5\n",
       "2  A must try.. great food great ambience. Thnx f...      5\n",
       "3  Soumen das and Arun was a great guy. Only beca...      5\n",
       "4  Food is good.we ordered Kodi drumsticks and ba...      5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the required columns\n",
    "review_rating_data = data[[\"Review\", \"Rating\"]]\n",
    "review_rating_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review    45\n",
      "Rating    38\n",
      "dtype: int64\n",
      "Review    0\n",
      "Rating    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(review_rating_data.isna().sum())\n",
    "\n",
    "# Drop rows with null values\n",
    "review_rating_data = review_rating_data.dropna()\n",
    "\n",
    "print(review_rating_data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "5       3826\n",
       "4       2373\n",
       "1       1735\n",
       "3       1192\n",
       "2        684\n",
       "4.5       69\n",
       "3.5       47\n",
       "2.5       19\n",
       "1.5        9\n",
       "Like       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the class distribution\n",
    "review_rating_data[\"Rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['5', '4', '1', '3', '2', '3.5', '4.5', '2.5', '1.5', 'Like'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique ratins in data\n",
    "review_rating_data[\"Rating\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7502/4064195984.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_rating_1_to_5_data[\"Rating\"] = review_rating_1_to_5_data[\"Rating\"].astype(int)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  The ambience was good, food was quite good . h...       5\n",
       "1  Ambience is too good for a pleasant evening. S...       5\n",
       "2  A must try.. great food great ambience. Thnx f...       5\n",
       "3  Soumen das and Arun was a great guy. Only beca...       5\n",
       "4  Food is good.we ordered Kodi drumsticks and ba...       5"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract rows with rating values in integers between 1 and 5\n",
    "review_rating_1_to_5_data = review_rating_data[review_rating_data[\"Rating\"].isin([\"1\", \"2\", \"3\", \"4\", \"5\"])]\n",
    "\n",
    "# Convert the ratings from strings to integers\n",
    "review_rating_1_to_5_data[\"Rating\"] = review_rating_1_to_5_data[\"Rating\"].astype(int)\n",
    "\n",
    "review_rating_1_to_5_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7502/613534455.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  review_rating_1_to_5_data[\"clean_text\"] = review_rating_1_to_5_data[\"Review\"].apply(lambda x: preprocess(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The ambience was good, food was quite good . h...</td>\n",
       "      <td>5</td>\n",
       "      <td>the ambience was good food was quite good had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ambience is too good for a pleasant evening. S...</td>\n",
       "      <td>5</td>\n",
       "      <td>ambience is too good for a pleasant evening se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A must try.. great food great ambience. Thnx f...</td>\n",
       "      <td>5</td>\n",
       "      <td>a must try great food great ambience thnx for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Soumen das and Arun was a great guy. Only beca...</td>\n",
       "      <td>5</td>\n",
       "      <td>soumen das and arun was a great guy only becau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food is good.we ordered Kodi drumsticks and ba...</td>\n",
       "      <td>5</td>\n",
       "      <td>food is ordered kodi drumsticks and basket mut...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  ...                                         clean_text\n",
       "0  The ambience was good, food was quite good . h...  ...  the ambience was good food was quite good had ...\n",
       "1  Ambience is too good for a pleasant evening. S...  ...  ambience is too good for a pleasant evening se...\n",
       "2  A must try.. great food great ambience. Thnx f...  ...  a must try great food great ambience thnx for ...\n",
       "3  Soumen das and Arun was a great guy. Only beca...  ...  soumen das and arun was a great guy only becau...\n",
       "4  Food is good.we ordered Kodi drumsticks and ba...  ...  food is ordered kodi drumsticks and basket mut...\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to preprocess the Reviews\n",
    "def preprocess(text):\n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Apply lowercasing and lemmatization if the token is alphanumeric and is not a punctuation\n",
    "    processed_tokens = [token.lemma_ and token.lower_ for token in doc if token.is_alpha and not token.is_punct]\n",
    "    # Join the token to form a string\n",
    "    return \" \".join(processed_tokens)\n",
    "\n",
    "# Apply preprocessing function to the dataframe\n",
    "review_rating_1_to_5_data[\"clean_text\"] = review_rating_1_to_5_data[\"Review\"].apply(lambda x: preprocess(x))\n",
    "\n",
    "review_rating_1_to_5_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    review_rating_1_to_5_data[\"clean_text\"],\n",
    "    review_rating_1_to_5_data[\"Rating\"],\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (7848,)\n",
      "X_test shape:  (1962,)\n",
      "y_train shape:  (7848,)\n",
      "y_test shape:  (1962,)\n"
     ]
    }
   ],
   "source": [
    "# Shapes\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The ngram_range parameter in CountVectorizer**\n",
    "\n",
    "ngram_range -> tuple (min_n, max_n), default=(1, 1)\n",
    "\n",
    "The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted.\n",
    "All values of n such such that min_n <= n <= max_n will be used.\n",
    "For example an ngram_range of (1, 1) means only unigrams, (1, 2) means unigrams and bigrams, and (2, 2) means only bigrams.\n",
    "\n",
    "Source: [Scikit-learn Docs](<https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unigrams and bigrams\n",
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "X_train_cv = vectorizer.fit_transform(X_train.values)\n",
    "X_test_cv = vectorizer.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['recommend',\n",
       " 'flavours',\n",
       " 'are',\n",
       " 'ambience',\n",
       " 'and',\n",
       " 'service',\n",
       " 'must',\n",
       " 'visit',\n",
       " 'ordered veg',\n",
       " 'veg pasta',\n",
       " 'pasta lasagne',\n",
       " 'lasagne butter',\n",
       " 'butter chicken',\n",
       " 'chicken biryani',\n",
       " 'biryani colsaw']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The vocabulary is a combination of unigrams and bigrams\n",
    "list(vectorizer.vocabulary_.keys())[15:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.70      0.76       416\n",
      "           2       0.06      0.53      0.10        15\n",
      "           3       0.07      0.34      0.12        47\n",
      "           4       0.32      0.44      0.37       348\n",
      "           5       0.92      0.62      0.74      1136\n",
      "\n",
      "    accuracy                           0.60      1962\n",
      "   macro avg       0.44      0.53      0.42      1962\n",
      "weighted avg       0.76      0.60      0.66      1962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and test the model\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(X_train_cv, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_cv)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of the Bag of N-Grams Model:\n",
    "1. Capturing Local Context\n",
    "\n",
    "    The Bag of N-Grams model's ability to identify the local context inside a text is one of its main benefits. The Bag of N-Grams model takes word sequences into account, in contrast to the Bag of Words model, which handles words separately. This method makes it possible to comprehend the connections between words more clearly. A bigram model, for instance, would preserve the context that a unigram model would lose in the sentence \"The quick brown fox,\" by recognizing \"quick brown\" and \"brown fox\" as significant units. This feature is especially helpful for jobs like sentiment analysis, where word combinations and order can drastically change the meaning of a statement.\n",
    "2. Better Performance in Specific Tasks Compared to Unigrams\n",
    "\n",
    "    The Bag of N-Grams model performs better than the more straightforward Bag of Words model in several natural language processing (NLP) tasks. This improvement is particularly apparent in activities where the context and word order play a significant role. For instance, bigrams and trigrams might offer more discriminative characteristics than individual words in text classification applications like spam detection or sentiment analysis. The model's capacity to take into account neighboring word pairs or triplets improves the analysis's accuracy and resilience by enabling it to identify phrases and expressions that are representative of particular categories or emotions.\n",
    "\n",
    "3. Flexibility in Choosing N\n",
    "\n",
    "    The versatility with which the Bag of N-Grams model may choose the value of N is another important benefit. It is possible to optimize efficiency by using varying numbers of N, depending on the text's nature and the particular job utilized. For instance, trigrams (N=3) may be more suited for jobs needing more context, such as named entity identification or complicated language modeling, yet bigrams (N =2) are frequently adequate for capturing local context in sentiment analysis. This adaptability strikes a compromise between model complexity and computing efficiency by enabling practitioners and academics to test various N values in pursuit of the best representation for their particular application. ## 7. The Bag of N-Grams Model's Limitations\n",
    "\n",
    "## Limitations of Bag of N-Grams Model:\n",
    "\n",
    "1. Curse of Dimensionality\n",
    "\n",
    "    The N-Gram Bag The curse of dimensionality, or the exponential increase in the number of features (N-Grams) as the size of the N increases, frequently affects models. For instance, a text corpus containing 10,000 distinct words in its lexicon can produce up to 10,000^2 bigrams (100 million) and 10,000^3 trigrams (1 trillion). There might be a lot of problems resulting from this sharp rise in the possible N-Gram population.\n",
    "\n",
    "    * Computational Complexity: Processing and analyzing huge datasets effectively is challenging since handling such a large feature set demands a substantial amount of memory and processing resources.\n",
    "\n",
    "    * Overfitting: When a model has too many features, it may overfit the training set and capture noise rather than broad trends. The model can no longer generalize to previously untested data as a result.\n",
    "\n",
    "2. Data Sparsity Issues\n",
    "\n",
    "    A further significant obstacle in the Bag of N-Grams Model is data sparsity. Many of the N-Grams that become more numerous may show up seldom or not at all in the text corpus.\n",
    "\n",
    "    * Sparse Feature Matrices: The numerous zeros in the generated feature matrices suggest that most papers don't have a lot of N-Grams. It costs a lot of computing power to store and work with sparse matrices.\n",
    "\n",
    "    * Inefficient Feature Utilisation: Many of the N-Grams that are produced could not provide the model with useful information, which might result in an inefficient use of resources and a possible decline in model performance.\n",
    "\n",
    "3. Lack of Semantic Understanding\n",
    "\n",
    "    * Ignoring Context: The model ignores the larger context in which N-Grams exist and interprets them as stand-alone units. For example, treating \"not good\" and \"good\" as separate bigrams would miss the negative connotation of the word \"not good.\"\n",
    "\n",
    "    * Word Meaning Clarification: Words with many meanings, or polysemous words, provide difficulties for the model. For instance, even if \"river bank\" and \"bank account\" have different meanings, the term \"bank\" in both would be handled similarly.\n",
    "\n",
    "    * Incapacity to collect Long-Distance Dependencies: Long-distance dependencies between words in a text are difficult for the model to collect and might be important information for deciphering the overall meaning of complicated sentences.\n",
    "\n",
    "4. Scalability Concerns\n",
    "\n",
    "    When using the Bag of N-Grams Model on large-scale text corpora, scalability is a major challenge. The restrictions listed above become more noticeable as the dataset gets larger.\n",
    "\n",
    "    * Resource Intensiveness: Processing big datasets with a lot of N-Gram features takes a lot of time and computing power. Scaling the model for large data applications is difficult as a result.\n",
    "\n",
    "    * Model Maintenance: It might be difficult to update and maintain models that were trained on huge, dynamic datasets regularly. Retraining is often required when the underlying data distribution changes and this requires a lot of resources.\n",
    "  \n",
    "    * Real-Time Processing: The significant processing cost of the Bag of N-Grams Model makes real-time text analysis unfeasible, which limits its use in time-sensitive applications like real-time sentiment analysis or spam detection.\n",
    "\n",
    "## Sources\n",
    "1. Youtube: Codebasics\n",
    "2. Javatpoint\n",
    "3. Restaurant Reviews Dataset: [Kaggle](https://www.kaggle.com/datasets/joebeachcapital/restaurant-reviews)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
