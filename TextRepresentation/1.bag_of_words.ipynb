{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "\n",
    "Bag of Words (BoW) is a text representation technique in Natural Language Processing. It is widely used to transform textual data into machine-readable format, specifically numerical values, without considering grammar and word order.\n",
    "\n",
    "A Bag of Words is based on the occurrence of words in a document. The process starts with finding the vocabulary in the text and measuring their occurrence. It is called a bag because the order and structure of words are not considered, just their occurrence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "Note: In any NLP pipeline, the first step is text preprocessing. Only after the text is preprocessed, the feature extraction technique of choice is applied.\n",
    "\n",
    "The sentences we are going to consider are:\n",
    "\n",
    "\"I love NLP.\"\n",
    "\"NLP is amazing!\"\n",
    "\n",
    "After preprocessing, we will obtain the two sentences in the form:\n",
    "\n",
    "\"love nlp\"\n",
    "\"nlp amazing\"\n",
    "\n",
    "1. Building the Vocabulary\n",
    "\n",
    "    Combine all documents or sentences into a corpus.\n",
    "\n",
    "    Identify all unique words in the corpus to create a vocabulary.\n",
    "    Vocabulary: [\"love\", \"nlp\", \"amazing\"]\n",
    "\n",
    "2. Representing Text as Vectors\n",
    "\n",
    "    Each document or sentence is converted into a vector based on the vocabulary. There are two variants of the bag-of-words model:\n",
    "\n",
    "    1. Word Presence: Binary encoding (1 if the word is present, 0 otherwise).\n",
    "        Example:\n",
    "       * \"love nlp\" → [1, 1, 0] \n",
    "       * \"nlp amazing\" → [0, 1, 1]\n",
    "\n",
    "    2. Word Frequency: Count the occurrences of each word.\n",
    "        Example:\n",
    "       * \"love nlp nlp\" → [1, 2, 0]\n",
    "       * \"nlp amazing nlp\" → [0, 2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using bag-of-words representation to build a spam email classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prerequisites\n",
    "1. Python 3.10 and above\n",
    "2. Pandas\n",
    "3. Spacy\n",
    "4. Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and inspect the first few samples of the dataset\n",
    "mail_data = pd.read_csv(\"./mail_data.csv\")\n",
    "mail_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Category\n",
       "ham     4825\n",
       "spam     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the class distribution of the data\n",
    "mail_data[\"Category\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Category column contains two labels, \"spam\" if the message is spam and \"ham\" if it is not.\n",
    "\n",
    "We will convert the category column into binary labels where 0 and 1 will represent ham and spam respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message\n",
       "0            0  Go until jurong point, crazy.. Available only ...\n",
       "1            0                      Ok lar... Joking wif u oni...\n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3            0  U dun say so early hor... U c already then say...\n",
       "4            0  Nah I don't think he goes to usf, he lives aro...\n",
       "...        ...                                                ...\n",
       "5567         1  This is the 2nd time we have tried 2 contact u...\n",
       "5568         0               Will ü b going to esplanade fr home?\n",
       "5569         0  Pity, * was in mood for that. So...any other s...\n",
       "5570         0  The guy did some bitching but I acted like i'd...\n",
       "5571         0                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mail_data[\"Category\"] = mail_data[\"Category\"].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "mail_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the message column is preprocessed for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "      <th>cleaned_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>jurong point crazy available bugis n great wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry wkly comp win fa cup final tkts tex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun early hor u c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah think goes usf lives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>time tried contact u won pound prize claim eas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity mood suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>guy bitching acted like interested buying week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message  \\\n",
       "0            0  Go until jurong point, crazy.. Available only ...   \n",
       "1            0                      Ok lar... Joking wif u oni...   \n",
       "2            1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3            0  U dun say so early hor... U c already then say...   \n",
       "4            0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...        ...                                                ...   \n",
       "5567         1  This is the 2nd time we have tried 2 contact u...   \n",
       "5568         0               Will ü b going to esplanade fr home?   \n",
       "5569         0  Pity, * was in mood for that. So...any other s...   \n",
       "5570         0  The guy did some bitching but I acted like i'd...   \n",
       "5571         0                         Rofl. Its true to its name   \n",
       "\n",
       "                                        cleaned_message  \n",
       "0     jurong point crazy available bugis n great wor...  \n",
       "1                               ok lar joking wif u oni  \n",
       "2     free entry wkly comp win fa cup final tkts tex...  \n",
       "3                                   u dun early hor u c  \n",
       "4                              nah think goes usf lives  \n",
       "...                                                 ...  \n",
       "5567  time tried contact u won pound prize claim eas...  \n",
       "5568                        ü b going esplanade fr home  \n",
       "5569                              pity mood suggestions  \n",
       "5570  guy bitching acted like interested buying week...  \n",
       "5571                                          rofl true  \n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans the input text using spaCy.\n",
    "    - Removes stopwords\n",
    "    - Removes punctuation\n",
    "    - Converts words to lowercase\n",
    "    - Converts words to their lemma\n",
    "    - Keeps only alphabetic tokens\n",
    "    \"\"\"\n",
    "    \n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    cleaned_tokens = []\n",
    "    \n",
    "    for token in doc:\n",
    "        if not token.is_stop\\\n",
    "        and not token.is_punct\\\n",
    "        and token.is_alpha:\n",
    "            token = token.lemma_ and token.lower_\n",
    "            cleaned_tokens.append(token)\n",
    "    \n",
    "    # Join the tokens again to form a sentence(a single string)\n",
    "    cleaned_text = \" \".join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "# Apply it to the message column\n",
    "mail_data[\"cleaned_message\"] = mail_data[\"Message\"].apply(lambda x: clean_text(x))\n",
    "\n",
    "mail_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_message</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jurong point crazy available bugis n great wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>free entry wkly comp win fa cup final tkts tex...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>u dun early hor u c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nah think goes usf lives</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>time tried contact u won pound prize claim eas...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ü b going esplanade fr home</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>pity mood suggestions</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>guy bitching acted like interested buying week...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>rofl true</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        cleaned_message  Category\n",
       "0     jurong point crazy available bugis n great wor...         0\n",
       "1                               ok lar joking wif u oni         0\n",
       "2     free entry wkly comp win fa cup final tkts tex...         1\n",
       "3                                   u dun early hor u c         0\n",
       "4                              nah think goes usf lives         0\n",
       "...                                                 ...       ...\n",
       "5567  time tried contact u won pound prize claim eas...         1\n",
       "5568                        ü b going esplanade fr home         0\n",
       "5569                              pity mood suggestions         0\n",
       "5570  guy bitching acted like interested buying week...         0\n",
       "5571                                          rofl true         0\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns we do not need\n",
    "cleaned_data = mail_data[[\"cleaned_message\", \"Category\"]]\n",
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape:  (4457,)\n",
      "X_test_shape:  (1115,)\n",
      "y_train_shape:  (4457,)\n",
      "y_test_shape:  (1115,)\n"
     ]
    }
   ],
   "source": [
    "# Split the cleaned data into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_data[\"cleaned_message\"], cleaned_data[\"Category\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the shapes\n",
    "print(\"X_train_shape: \", X_train.shape)\n",
    "print(\"X_test_shape: \", X_test.shape)\n",
    "print(\"y_train_shape: \", y_train.shape)\n",
    "print(\"y_test_shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# Data types\n",
    "print(type(X_train))\n",
    "print(type(X_test))\n",
    "print(type(y_train))\n",
    "print(type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get bag-of-words representation of the text\n",
    "vect = CountVectorizer()\n",
    "\n",
    "# X_train and X_test are pandas Series objects,\n",
    "# the .values property returns the values in an array without the indexes\n",
    "X_train_cv = vect.fit_transform(X_train.values)\n",
    "X_test_cv = vect.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6252"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary length\n",
    "len(vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 6252)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of the first sentence in the training data, it will be (1, vocabulary length)\n",
    "print(X_train_cv[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       966\n",
      "           1       0.93      0.93      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "# Fit the training data to the model\n",
    "mnb.fit(X_train_cv, y_train)\n",
    "\n",
    "# Get predictions\n",
    "y_pred = mnb.predict(X_test_cv)\n",
    "\n",
    "# Generate classification report\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       966\n",
      "           1       0.93      0.93      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.96      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A compact way of doing vectorization and modelling is to use a Pipeline\n",
    "clf = Pipeline([\n",
    "    (\"Vectorizer\", CountVectorizer()),\n",
    "    (\"Naive Bayes\", MultinomialNB())\n",
    "])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages\n",
    "\n",
    "1. **Simple to implement and interpret**: The Bag of Words model is one of the most straightforward text representation techniques, making it ideal for beginners. Its simplicity allows for fast implementation without the need for complex preprocessing or specialized models.\n",
    "   \n",
    "2. **Easy to use for text classification tasks**: Bag of Words is well-suited for basic tasks like text classification, sentiment analysis, and spam detection. These tasks often don’t require sophisticated language models, so a BOW representation is sufficient and efficient.\n",
    "\n",
    "## Disadvantages\n",
    "\n",
    "1. **Produces sparse matrices that are computationally expensive**: Since each document is represented by the frequency of each word in a potentially large vocabulary, the resulting matrices are often mostly zeros, which can be inefficient to store and process in machine learning pipelines. Sparse matrices consume significant memory and often require specialized tools and libraries for efficient storage and computation, especially with large datasets.\n",
    "\n",
    "2. **Loses meaning and context**: BOW disregards word order and sentence structure, which results in the loss of grammatical relationships and meaning. This limitation makes it less suitable for tasks where context, nuance, and word order matter, such as translation or sentiment detection in complex sentences.\n",
    "\n",
    "3. **Out-of-Vocabulary (OOV) issues**: New or unseen words are not represented in the vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "1. Youtube: Krish Naik, Codebasics\n",
    "   \n",
    "2. Datacamp: Derrick Mwiti\n",
    "   \n",
    "3. Spam Email Dataset: [Kaggle](<https://www.kaggle.com/datasets/abdmental01/email-spam-dedection>)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
